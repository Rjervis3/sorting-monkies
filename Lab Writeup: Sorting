Lab Writeup: Sorting

Renn Jervis and Kieran Connoly

1-5, 8-14, 17-22, 24-25, 27-30.

1. Considering the following array and k = 8 we have the following steps
in an insertion sort:
    0 1 2 3  4  5  6  7 
  [ 3 7 9 10 18 27 33 37] , i = 7, k = 8, a[item]=17

-> Move through the array beginning with a[i] and shift elements right while
a[i] is greater that 17. Thus we shift 37, 33, 27, and 18. Finally, a[Item] is
inserted at index 4 as this is its correct place. Now we have 
[ 3 7 9 10 17 18 27 33 37 ].

2. Now considering the same situation but with a[item] = 40, we have:
    0 1 2 3  4  5  6  7 
  [ 3 7 9 10 18 27 33 37] i = 7 k = 8 a[item]=40

  -> We move through the elements while a[i] is greater than 40 and shift things
  right to make space for the insertion. In this case no elements are greater 
  than 40, so our while loop does not move i. Thus we insert at a[i+1], in this
  case at then end of the array. Now we have  [ 3 7 9 10 18 27 33 37 40 ].

3. Now considering the same situation but with a[item] = 2, we have:
    0 1 2 3  4  5  6  7 
  [ 3 7 9 10 18 27 33 37] i = 7 k = 8 a[item]=2

  -> In this case we move left through the array searching for an element that
  is less than a[item]. As we search we shift all elements to the right one 
  place. As no elements in this array are smaller than 2, the deincrementing of 
  i continues until we shift the element at a[0] to a[1]. Since now i is -1
  the while loop will not continue, and we insert a[item] at i+1 th index, in 
  this case at index 0. Now we have [ 2 3 7 9 10 18 27 33 37].

4. As we saw in problem 3, the test i>=0 ensures that we do not test indicies
  outside of the range of the array, and also ensures that if we are inserting 
  the smallest element, this element will be inserted at index 0.

5. Insertion sort adds items in their corect place to an already sorted array.
  We being by chosing a[k] to insert into the (necessarily) ordered segment
  a[0]. Obviously, if a[k] > a[k-1] we insert it at the next index. If 
  a[k] < a[k-1] we slide a[k] right and insert our element at a[i+1]. This
  processing continues for each element to be inserted (we process the whole
  array). K is the index of the element such that a[0] ... a[k-1] is already
  ordered, a[item]= a[k] is the item we are currently looking to insert
  into the ordered section, and a[i] is the element we are currently comparing 
  to a[item]. The while loop in the code determines the 
  correct insertion position for each new element.

7. Modify insertion sort so it sorts in decending order:

public static void insertionSort (int [] a) {
// method to sort using the insertion sort
   for (int k = 1; k < a.length; k++) {
      int item = a[k];
      int i = k-1;
      while ((i >= 0) && a[i] < item){
         a[i+1] = a[i];
         i--;
      }
      a[i+1] = item;
   }
} // insertionSort

-> Simply change the while condition to a[i] < item. Tested with SortShell.java.
 test run:

Please enter 12 integer values to sort, with each number on a separate line
5
6
3
2
4
5
7
9
2
3
4
4
Result of Insertion Sort:
9 7 6 5 5 4 4 4 3 3 2 

------------------------------Quicksort-------------------------------------

8. Considering Loop Invariant 1 and the following array segment:

  0 1  2 3  4 5 6  7  8 9 10 11 12
[10 6 16 8 14 2 4 18 12 13 1  5  20]

-> The element at index 0 will be our partition element, ie a[first]. The left
variable will be initialized to 1 because a[left] = 6 is the first element we
want to consider when searching for an element less that a[first]. The right
variable will be initialized to 12, since that is the index of the last element
we want to process. Right moves until it finds something that is smaller than 
a[first] (in this case our first stop is at right = 11), and left continues 
until it finds an element such that a[left] > a[item] (in this case our first 
stop is at left = 2). We flip these elements and continue with processing. Our 
next swap will be a[4] and a[10], because 14 > 10 and 1 < 10. We now have
right = 10 and left = 4. The while loop will continue adjusting left and right
until they are at positions right =6 and left = 7. Now we swap the partition 
element into place by swapping the values a[first] with a[right]. This gives
us the final segment 
 0 1 2 3 4 5 6  7  8  9  10  11  12
[4 6 5 8 1 2 10 18 12 13 14  16  20].

9. Given an array in ascending order:
  0 1 2 3 4
[ 1 2 3 4 5]
We begin with a[first] as our partition element, right as 4 and left as 1. Right
moves right until we find something such that a[right]<a[first]. Since this does 
not ever happen, we move until right is at index 0. Left stays at its current 
location because a[left] > a[first], but no swapping occurs because right <left.
Thus no initial swapping occurs and we procede to move our partition element 
into the right place. This swaps a[first] with a [right] (in this case 
first == right) which changes nothing in this case.

10. Given an array in decending order:
 0 1 2 3
[4 3 2 1]
-> We begin with the first = 0, and so our partition element is 4. Right is 3 
and left is 1. Right seeks an element smaller that the pivot, and so does not
need to be decremented. Right remains at 3 and left moves past 
right (in search of a large entry) to index 4. We exit our while loop and swap
the partition into its place, namely a[right]. This produced [1 3 2 4].

11. If right is less than left, that means we have processed all of the elements
and we ought to exit our while without completing any swaps. For example,
consider array [5 1 2 4]. Right begins at 3 and left at 1. Since our partition 
element is 5, right does not move since a[right] < pivot. Left searches for a 
large element and in doing so moves past right (because it does not find one). 
Now right < left, and left is outside the bounds of the array, so we definitly
do not want to swap it's (mystery) value into the array!

12. The code contains the check right>=left to enforce our loop invariant which
says that we want to continue until all of the elements have been processed and
everything to the right of a[right] is greater than or equal to a[first] and 
similarly that everything to the left of a[left] is smaller than or equal to
a[first]. Given the example array [4 6 5 8 1]:
our partition element is 4, right is 4 and left is 1. Right moves until it 
locates an element smaller than the partition, and so stays at 4. Left seeks a 
value greater than 4 and also does not have to move. We swap a[right] and 
a[left] and now have [4 1 5 8 6]. Right moves to find a small element and gets
to index 1. Left is simply decremented by one. Now we have right = 1 and
left = 2. If the loop exit conditiion were something else, we would keep moving 
left and right and they would not end up in the correct position. The equals
sign in the test is also important, for example if after some loop right and 
left are equal, we have no gaurentees that the element they refer to is in 
the correct place (we only know everything to the right of right is larger than
the pivot and everything to the left is smaller), and so we must continue the
loop until right has passed left and we can safely swap the pivot into its spot.

13. The husk procedure provides slightly more information as to which portion
of the array we are to consider because it gives us a right and a left bound
for processing. This code uses the partitioning method utilized earlier to 
recursively sort an array. It begins by partitioning the array with the initial 
partition (ie puts the first elemet of the array into its correct location) and 
then proceeds to recursivly partition smaller and smaller sections of each side
to achieve a sorted array. The husk procedure is necessary if we want to work 
with the original array each time; because our partition method uses the
first element of the array given as the pivot element, we need a way to 
specify which element we want to be the pivot and how much of the array we want
to consider (in other words we need a top and bottom bound so our recursive
call sorts a different portion of the array each time).

// (The husk procedure is necessary because we must start the procedure by
specifying the array that we are sorting. This can only occur once, as we
are operating recursively and must change these parameters in each
recursive call, hence the husk.)

14. The base case in the recursion arises when one element sections are being 
partitioned. As we call quicksort on smaller and smaller sections of the array,
eventually it will be called on a one-element section. When this happens, 
first and last will be the same, and so right becomes left-1. Thus we skip the 
while loop, swap the element with itself, and return. The recursive calls only
porcede if we have more than 2 elements.


//(Also true with two-element sections. 
Another base case is where there are two elements. If we are passed two
elements, left and right, the algorithm will sort them if unosrted or leave
them alone if sorted. The two tests will fail. In the first case, right-1
will be either less than or equal to first, and in the second case, right+1
must be greater than or equal to last.  

16. Modify quicksort to sort in decending order:

 modify the inner while loop:
 while (right >= left) {
        // search left to find small array item
        while ((right >= left) && (a[first] >= a[right]))
            right--;
        // search right to find large array item
        while ((right >= left) && (a[first] <= a[left]))
            left++;
        // swap large left item and small right item, if needed
        if (right > left) {
            temp = a[left];
            a[left] = a[right];
            a[right] = temp;
        }
    }

tested with ShellSort2.java:
Test run example;
Please enter 12 integer values to sort, with each number on a separate line
4
5
6
7
8
3
5
6
7
4
2
2
Result of Quicksort:
8 7 7 6 6 5 5 4 4 3 2 2


17. Program ShellSort3 uses a random element for the partition element instead
of the first element in the array. Statistically this probably means we will
have a better average run time, especially for decending arrays.

-----------------------------Quicksort approach 2 -----------------------------

18. In this quicksort approach, we wish to maintain that the first element is 
our partition element, the section from a[first+1] ... a[left-1] is populated
with elements <= a[first], the section a[left] ... a[right-1] is >= a[first], 
and the section a[right] ... a[last] is unprocessed. When we being processing, 
we see that the 'then' condition of the if statement maintains the right 2
segments--if the value is classified to belong in the middle section 
(val > a[first]), then we simply increase the size of the middle portion to 
include that element. The else clause maintains the above invariant because
if the value is determined to belong in the first section (ie is less than
a[first]), then we place the first unprocessed element in the left section
by swapping it with the lowest right value. Since we have added a value to
the left section, we increment the boundary of left, and since we retain the 
values in right by moving the (previously) first to the last, we also increment
right.

19. The code swaps a[first] with a[left-1] because a[left] is infact the first
element in the right (greater than pivot) section. We want a[first] to be
swapped so that everything to the right is larger and everything to the left is
less than or equal to.

20. The loop gaurd for this version is right<=last because when our right index
has moved beyond the bounds of the array, we know we have processed every
element. Recall this is because everything to the left of a[right] has been
processed, and so a[right] is in fact the first unprocessed element.

21. The first recursive call uses left-2 as the right bound because we have just
swapped the pivot element into left-1, thus left-2 is the rightmost index of 
the lefthand side of the array. The second recursive call uses left as its 
leftmost index because a[left] is defined as the first element in the right
section (section of values larger than partition).


22.
a) Considering Loop Invariant 2 and the following array segment:

  0 1  2 3  4 5 6  7  8 9  10 11 12
[10 6 16 8 14 2 4 18 12 13 1  5  20]
-> We begin with left and right at 1, choose a random partition element, 
swap it into index 0 in array, and proceed with partitioning. Assuming we chose
10 as our partition element, sice a[right] = 6 < 10 the if 
statement fails and we swap a[left] and a[right] (same element) and increment 
both indicies. Now the if condition is true (a[right] = 16 > a[first]= 10) and 
so we increment right. Now the if condition fails and we swap left and right and
increment both indicies. Now we have [10 6 8 16 14 2 4 18 12 13 1  5  20]
Two more times the if condition is true (a[right] = 16 > 10, a[right] = 14 > 10) 
so we increment right twice. Now the if condition fails, we swap left and right
(left = 3, right = 5) and increment both left and right to obtain 
[10 6 8 2 14 16 4 18 12 13 1 5 20]. Again perform swap step to obtain
[10 6 8 2 4 16 14 18 12 13 1 5 20]. Now three more times the if condition is 
true (a[right] = 18 < 10, a[right] = 12 < 10, a[right] = 13) so we increment
right 3 times. Now when right = 10 and left = 5 we swap 16 and 1 to get
[10 6 8 2 4 1 14 18 12 13 16 5 20]. Increment the indicies, the if statement
fails, and we swap a[left] = 14 and a[right] = 5 to get  
[10 6 8 2 4 1 5 18 12 13 16 14 20]. Both indicies are incremented and one final
test of the if statement results in a final incrementation of right. Now 
left = 7 and right = 13. Because right > last, we break out of the while loop
and perform the last swap of the pivot into place. a[left-1] is the last element
in the section designated < pivot, and so this is the index we want to swap with
the pivot. Final partitioned array:
[5 6 8 2 4 1 10 18 12 13 16 14 20]

b) Given an array in ascending order:
  0 1 2 3 4
[ 1 2 3 4 5]
We choose a random partion element (in this case 4) and swap it to the beginning
of the array. We now have [4 2 3 1 5], and left and right are both 1.
a[right] = 2 < 4 so the if statment fails and we swap right and left and 
increment both indicies. Now a[right] = 3 < 4 so we swap 3 with itself and 
increment both indicies. Now a[right] = 1 < 4 so we swap 1 with itself and
increment both counters. Now a[right] = 5 > 4 so we increment right. Now right
is 5 and left is 4. We break out of the while loop and swap the partition 
element into a[left-1] this gives partitioned array : [1 2 3 4 5]


c) Given an array in decending order:
 0 1 2 3
[4 3 2 1]
We choose a random partition element (in this case 3) and swap it to the 
beginning of the array: [3 4 2 1]. Right and left are both 1 and so the 
conditional passes and we increment right (because a[right] = 4 >3 ). Now we
swap left and right and increment both indicies to get [3 2 4 1]. The
conditional fails and we swap left and right to get [3 2 1 4]. Both indicies
are incremented and now right = 4 and we break out of the while loop. We swap
the partition element into its place at a[left-1] to get [1 2 3 4].

---------------------Analysis and Timing--------------------------------------

24. 
-> Consider that the first partition divides the array into 2 sections. If the
pivot index is m and the first and last elements are i and j respectively, then
we have T(n) (time to sort n els) = T(m) + T(n-m)

The absolute worst case of quicksort is when we choose the smallest (or largest)
partition element each time. We partition the array into 2 sections, 1 with 1 
value and the other with the remaining n-1 values. Sorting this invovles O(n)
recursive calls as we sort the non empty segment. If we choose this worst case
partition element each time this case has O(n^2). This is very unlikely given
the randomization of our pivot choice.

The (other) bad cases are wwhen one or more choices of the pivot are the 
smallest (or largest) element in the array. This is because we have one section
of the array with n-1 elements to sort recursively. If the rest of the recusions
perform averagely after one 'bad' choice of partition, we expect this to be 
(nlogn)

The best case is when the pivot chosen is the median. Both sides are the
same size and we sort them recursively. T(n) = 2 times the amount of time
it takes to sort half the array T(n/2). If we continue to choose a number 
close to the median pivot each time we expect the runtime to have 0()

25. If each algortith requires t miliseconds to sort N items, we would expect
that the algortihm would take t + ??? to sort 2N items. When we double
the number of items


27. Modified program SortShell5.java

 Insertion Sort
          Ascending data      Random Data         Descending Data
 10000         1                   55                  105   
 20000         2                   203                 402  
 40000         3                   811                 1583   
 80000         3                   738                 1502
 160000        5                   3005                6012

QuickSort
          Ascending data      Random Data         Descending Data
 10000         22                  21                    15    
 20000         48                  37                    35   
 40000         64                  50                    40   
 80000         49                  24                    47
 160000        68                  77                    22

RefQuickSort
          Ascending data      Random Data         Descending Data
 10000          27                 22                    14
 20000          40                 38                    32   
 40000          52                 41                    39   
 80000          17                 45                    40
 160000         43                 55                    20


28. Our data tabulation found results that seem consistant with our above
analysis and the analysis of insertion sort in class. As we increased by 
a factor of 2 the Intertion sort -- for ascending data, ---for random data, and
--- for descending data. The quicksort has a slight outlier in the ascending 
data in ?? and seems to handle all data types about the same. The refined 
quciksort seems to comply with expected analysis ( ) and overall seemed to
handle all types of data with similar time and performed well as we continued
to double N.

29. The alternate approach for the quicksort ---

30. The refined quicksort--because of the random choice of pivot--ought to
 perform with reasonably the same efficiency on all types of data. 

